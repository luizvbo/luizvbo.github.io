@inproceedings{oliveira2018analysing,
 abstract = {The definition of a concise and effective testbed for Genetic Programming (GP) is a recurrent matter in the research community. This paper takes a new step in this direction, proposing a different approach to measure the quality of the symbolic regression benchmarks quantitatively. The proposed approach is based on meta-learning and uses a set of dataset meta-features---such as the number of examples or output skewness---to describe the datasets. Our idea is to correlate these meta-features with the errors obtained by a GP method. These meta-features define a space of benchmarks that should, ideally, have datasets (points) covering different regions of the space. An initial analysis of 63 datasets showed that current benchmarks are concentrated in a small region of this benchmark space. We also found out that number of instances and output skewness are the most relevant meta-features to GP output error. Both conclusions can help define which datasets should compose an effective testbed for symbolic regression methods.},
 address = {Kyoto, Japan},
 author = {Luiz Otavio V. B. Oliveira and Joao Francisco B. S. Martins and Luis F. Miranda and Gisele L. Pappa},
 booktitle = {Proceedings of Genetic and Evolutionary Computation Conference Companion, 2018 (GECCO'18 Companion)},
 doi = {https://doi.org/10.1145/3205651.3208293},
 month = {July},
 title = {Analysing Symbolic Regression Benchmarks under a Meta-Learning Approach},
 url = {https://arxiv.org/abs/1805.10365},
 year = {2018}
}

